<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="SynergAI">
  <meta property="og:title" content="SynergAI: A Unified System for Zero-shot 3D Reasoning and Human-Robot Alignment."/>
  <meta property="og:description" content="An LLM-based system that addresses perceptual misalignment with human-robot alignment in real-time."/>
  <meta property="og:url" content="https://synerg-ai.github.io"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="SynergAI: A Unified System for Zero-shot 3D Reasoning and Human-Robot Alignment.">
  <meta name="twitter:description" content="An LLM-based system that addresses perceptual misalignment with human-robot alignment in real-time.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Human-Robot Alignment">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>SYNERGAI</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-size-1 publication-title">SYNERGAI: A Unified System for Zero-shot 3D Reasoning and Human-Robot Alignment</h1>
                    <div class="is-size-4 publication-authors">
                        <span class="author-block">
                            <a href="https://yixchen.github.io" target="_blank">Yixin Chen</a><sup>*</sup>,
                        </span>
                        
                        <span class="author-block">
                            <a href="https://guoxizhang.com" target="_blank">Guoxi Zhang</a><sup>*</sup>,
                        </span>
                  
                        <span class="author-block">
                            Yaowei Zhang<sup>*</sup>,
                        </span>

                        <span class="author-block">
                            <a href="https://sbx126.github.io" target="_blank">Hongming Xu</a><sup>*</sup>,
                        </span>
                 
                        <span class="author-block">Peiyuan Zhi,</span>
                  
                        <span class="author-block">
                            <a href="https://liqing.io" target="_blank">Qing Li</a><sup>&#x1f4e7;</sup>,
                        </span>

                        <span class="author-block">
                            <a href="https://siyuanhuang.com" target="_blank">Siyuan Huang</a><sup>&#x1f4e7;</sup>
                        </span>
                    </div>

                    <div class="is-size-4 publication-authors">
                        <span class="author-block">Beijing Institute for General Artificial Intelligence (BIGAI)<br>Preprint</span>
                        <span class="is-size-5 eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                    </div>
                </span>
                <span class="link-block">
                    <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
            </div>
        </div>
        <hr class="solid">
    </div>
</section>
                  <!-- <div class="column has-text-centered"> -->
                    <!-- <div class="publication-links"> -->
                         <!-- Arxiv PDF link -->
                      <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                
                
            <!-- </div> -->
          



<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop has-text-centered">
    <div class="hero-body">
        <span class="is-size-5 eql-cntrb"> <b>TL;DR:</b> We introduce SYNERGAI, a LLM-based system that can align and collaborate on 3D reasoning tasks with humans in a zero-shot manner.</span>
        </br>
      <iframe height="486" width="864" src="https://www.youtube.com/embed/Eol_8tWI9ac"></iframe>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero">
    <div class="container  is-max-desktop">
        <div class="hero-body">
            <div class="columns is-centered has-text-centered">
                <div class="column is-max-desktop">
                    <h2 class="title is-size-2">Abstract</h2>
                    <div class="is-size-5 content has-text-justified">
                        <p>
                            Recently, large language models (LLM)s have shown promise in robotics, offering powerful capabilities from task planning to commonsense reasoning. <b>However, existing LLM-based robotic systems often overlook the misalignment between human and robot perceptions, hindering their deployment in real-world scenarios.</b> To address this issue, we introduce SYNERGAI, a unified system designed to achieve zero-shot 3D reasoning and human-robot alignment. SYNERGAI reconstructs 3D scenes and generates 3D Scene Graphs (3DSG)s as its innate representation. It leverages LLMs to break down complex 3D reasoning tasks into intermediate steps and allocate appropriate tools for completing these steps. 
                            Importantly, SYNERGAI incorporates an alignment mechanism allowing users to correct perceptual misalignment with the robot in real-time.
                            All functionalities of SYNERGAI are seamlessly integrated into a user-friendly graphical interface, enabling intuitive interactions such as dragging, zooming, object marking, and natural-language instructions. 
                            In a zero-shot manner, SYNERGAI achieves comparable performance with the state-of-the-art models in ScanQA.
                            Additionally, a comprehensive user study confirms its effectiveness in establishing common ground with humans, significantly improving answer accuracy from 4.76% to 61.9%, with a high user satisfaction ratio of 64.87%.
                            In conclusion, SYNERGAI offers a powerful, versatile, and agile solution for human-robot collaboration, poised to advance the deployment of robot assistants in real-world scenarios.
                        </p>
                    </div>
                </div>
            </div>
        <!-- </div><hr class="solid"> -->
    </div>
</section>
<!-- End paper abstract -->
<section class="section hero">
    <div container>
        <div class="container  is-max-desktop">
            <h2 class="title is-size-2 has-text-centered">Approach</h2>
            <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                    <img src="static/images/teaserv2.jpg" alt="MY ALT TEXT"/>
                    <h2 class="is-size-5 subtitle ">
                    <b></br>1. An overview of SYNERGAI.</b> By representing 3D scenes as 3DSGs, SYNERGAI can perform zero-shot 3D reasoning and human-robot alignment. In particular, we introduce mouse clicking to facilitate object reference in the presence of errourneous perception.
                    </h2>
                </div>
                <div class="item">
                    <img src="static/images/agent_design.png" alt="MY ALT TEXT"/>
                    <h2 class="is-size-5 subtitle">
                        <b></br>2. The design of SYNERGAI and an example interaction.</b> SYNERGAI takes text inputs from a user and progressively collect information from the 3DSG to generate responses, during which it operates a 3DSG through a set of APIs called <em>tools</em>. As shown in the example interaction, it generates a plan first and resolves the user input step-by-step. In this example, the system incorrectly recognizes the object of interest as a book, which indicates perception misalignment.
                    </h2>
                </div> 
                <div class="item">
                    <img src="static/images/tools.jpg" alt="MY ALT TEXT"/>
                    <h2 class="is-size-5 subtitle">
                    </br><b>3. The set of tools developed for SYNERGAI.</b> Theses tools support accessing objects and relations (the top five) and modifying information in 3DSGs as requested (the following four). The last two tools are for generating responses to the user.
                    </h2>
                </div> 
            </div>
        </div>
        <!-- </div><hr class="solid"> -->
    </div>
</section>

<section class="section hero">
    <div container>
        <div class="container  is-max-desktop">
            <h2 class="title is-size-2 has-text-centered">Evaluation</h2>
            <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                    <img src="static/images/3d_reasoning_qualitative.jpg" alt="MY ALT TEXT"/>
                    <h2 class="is-size-5 subtitle">
                    </br> <b>1. Qualitative results for 3D reasoning tasks.</b> SYNERGAI can solve multiple 3D reasoning tasks with a unified design.
                    </h2>
                </div>
                <div class="item">
                    <img src="static/images/alignment_task_example.jpg" alt="MY ALT TEXT"/>
                    <h2 class="is-size-5 subtitle">
                    </br> <b>2. Examples of EASY and HARD alignment tasks.</b> We device 42 tasks to assess SYNERGAI's capability for human-robot alignment. The questions in the tasks are challenging in the presence of perception errors but can be resolved after human-robot alignment. In specific, in the right example the user notices from the system response that both the hanger and the
                    ironing board have incorrect labels. Thus the user checks and corrects the label of the ironing board
                    by clicking (the 2nd and 3rd user inputs). Then the user checks the items to the left of the ironing
                    board (the 4th input) and corrects the label of the hanger (the 5th and 6th inputs).
                    </h2>
                </div> 
                <div class="item">
                    <img src="static/images/alignment_quantitative.jpg" alt="MY ALT TEXT"/>
                    <h2 class="is-size-5 subtitle">
                    </br><b>3. Quantitative results for human-robot alignment experiments.</b> In our experiment, 10 human subjects are recruited to interact with our system and correct perception errors so that the system can answer the questions in the alignment tasks. Our results show that the users are quite satified with the system's responses (Interaction SR=64.87%), and the answer accuracy is improved from 4.76% to 61.9% after alignment. 
                    </h2>
                </div> 
            </div>
        </div>
    </div>
</section>


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section hero" id="BibTeX">
    <div class="container  is-max-desktop">
      <h2 class="title is-size-2 has-text-centered">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<section class="section hero">
    <div class="container is-max-desktop">
        <hr class="solid">
        <div class="columns has-text-centered">
            <p><a href="https://www.bigai.ai" target="_blank"><img src="static/images/bigai.png" alt="BIGAI logo" class="center-image" width=25% textalign="center"/></a></p>
        </div>
    </div>
</section>

<!-- <footer class="footer">
    <div class="imgcontainer is-max-desktop">
        <div class="columns is-centered">
          <!-- <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. -->
            <!-- <a href="https://www.bigai.ai" target="_blank"><img src="static/images/bigai_ml2.jpg" alt="BIGAI logo" class="center-image" width=100%/></a> -->
            <!-- <a href="https://www.bigai.aih" target="_blank"><img src="static/images/bigai_ml.jpg" alt="ML logo" class="center-image" width=100%/></a> -->
        <!-- </div>
        
    </div> -->
<!-- </footer> -->



<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
